# Day 024: Comprehensive Testing Review

**Month 1:** Lox Lexer & Go Fundamentals
**Phase:** Foundation
**Week:** 4 of 4

---

## üéØ Today's Goal

Run the complete test suite, analyze coverage, and ensure all edge cases are handled. Document testing approach and verify the lexer is bulletproof.

**Focus:** Test coverage, edge cases, and test documentation

---

## üìö Learning Focus

- Go Testing
- Test Coverage Analysis
- Edge Case Testing
- Test Documentation

**This Week:** REPL, testing & documentation

---

## ‚úÖ Tasks

### 1. Run Full Test Suite & Coverage Analysis (45 min)

**Objective:** Verify all tests pass and measure code coverage.

**Action Items:**

Run comprehensive test commands:

```bash
# Run all tests with verbose output
go test ./... -v

# Run tests with coverage
go test ./... -cover

# Generate detailed coverage report
go test ./... -coverprofile=coverage.out

# View coverage in browser (creates HTML report)
go tool cover -html=coverage.out -o coverage.html

# Open in browser (Linux)
xdg-open coverage.html
```

**Analyze coverage results:**

Expected coverage targets:
- **Overall:** 80%+ coverage
- **pkg/lexer/scanner.go:** 90%+ (core logic)
- **pkg/tokens/token.go:** 100% (simple logic)
- **cmd/lox/main.go:** Lower coverage OK (I/O heavy)

**What to look for:**

1. **Uncovered lines:** Lines that never execute in tests
2. **Red sections:** Code paths not tested
3. **Green sections:** Well-tested code

**Checklist:**
- [ ] All tests passing (0 failures)
- [ ] Coverage report generated
- [ ] Coverage meets targets (80%+)
- [ ] Critical paths have 100% coverage
- [ ] Identified any untested code

**Document findings:**
```bash
# Save coverage stats
go test ./... -cover > test-results.txt
```

---

### 2. Edge Case Testing (90 min)

**Objective:** Identify and test edge cases that might not be covered.

**Edge cases to verify:**

#### String Literals
```go
// Test cases to add if missing
func TestScanTokens_StringEdgeCases(t *testing.T) {
    tests := []struct {
        source      string
        description string
        wantError   bool
    }{
        {`""`, "empty string", false},
        {`"single char: a"`, "single character", false},
        {`"unicode: ‰Ω†Â•Ω"`, "unicode characters", false},
        {`"escape: \n \t"`, "escape sequences", false},
        {`"unterminated`, "unterminated string", true},
        {`"multi\nline"`, "multiline string", false},
        {`"has \"quotes\""`, "quoted quotes", false},
    }

    for _, tt := range tests {
        t.Run(tt.description, func(t *testing.T) {
            scanner := NewScanner(tt.source)
            _, errs := scanner.ScanTokens()

            if tt.wantError && len(errs) == 0 {
                t.Errorf("expected error for %s", tt.description)
            }
            if !tt.wantError && len(errs) > 0 {
                t.Errorf("unexpected error for %s: %v", tt.description, errs)
            }
        })
    }
}
```

#### Number Literals
```go
func TestScanTokens_NumberEdgeCases(t *testing.T) {
    tests := []struct {
        source      string
        wantLiteral float64
        description string
    }{
        {"0", 0.0, "zero"},
        {"0.0", 0.0, "zero float"},
        {"123.456", 123.456, "decimal number"},
        {"999999999", 999999999.0, "large number"},
        {"0.0001", 0.0001, "small decimal"},
        {"42.0", 42.0, "whole number as float"},
    }

    for _, tt := range tests {
        t.Run(tt.description, func(t *testing.T) {
            scanner := NewScanner(tt.source)
            toks, errs := scanner.ScanTokens()

            if len(errs) > 0 {
                t.Fatalf("unexpected error: %v", errs)
            }

            if toks[0].Literal != tt.wantLiteral {
                t.Errorf("got %v, want %v", toks[0].Literal, tt.wantLiteral)
            }
        })
    }
}
```

#### Identifiers & Keywords
```go
func TestScanTokens_IdentifierEdgeCases(t *testing.T) {
    tests := []struct {
        source   string
        wantType tokens.TokenType
    }{
        {"_", tokens.IDENTIFIER},          // single underscore
        {"_foo", tokens.IDENTIFIER},       // starts with underscore
        {"foo_", tokens.IDENTIFIER},       // ends with underscore
        {"foo123", tokens.IDENTIFIER},     // contains numbers
        {"varx", tokens.IDENTIFIER},       // keyword prefix
        {"var", tokens.VAR},               // actual keyword
        {"variable", tokens.IDENTIFIER},   // keyword inside
        {"and123", tokens.IDENTIFIER},     // keyword prefix + numbers
    }

    for _, tt := range tests {
        scanner := NewScanner(tt.source)
        toks, _ := scanner.ScanTokens()

        if toks[0].Type != tt.wantType {
            t.Errorf("%s: got %v, want %v", tt.source, toks[0].Type, tt.wantType)
        }
    }
}
```

#### Whitespace & Line Tracking
```go
func TestScanTokens_WhitespaceAndLines(t *testing.T) {
    source := "var x\n\n\n= 5;"
    scanner := NewScanner(source)
    toks, _ := scanner.ScanTokens()

    // Should properly track line numbers across blank lines
    expectedLines := []int{1, 1, 4, 4, 4} // var, x, =, 5, ;

    for i, tok := range toks[:len(toks)-1] { // Exclude EOF
        if tok.Line != expectedLines[i] {
            t.Errorf("token %d: got line %d, want %d",
                i, tok.Line, expectedLines[i])
        }
    }
}
```

#### Error Handling
```go
func TestScanTokens_ErrorHandling(t *testing.T) {
    tests := []struct {
        source       string
        wantErrorCnt int
        description  string
    }{
        {"@", 1, "invalid character"},
        {"#", 1, "hash symbol"},
        {`"unterminated`, 1, "unterminated string"},
        {"@ # $", 3, "multiple errors"},
        {"var x @ 5;", 1, "error mid-program"},
    }

    for _, tt := range tests {
        t.Run(tt.description, func(t *testing.T) {
            scanner := NewScanner(tt.source)
            _, errs := scanner.ScanTokens()

            if len(errs) != tt.wantErrorCnt {
                t.Errorf("got %d errors, want %d: %v",
                    len(errs), tt.wantErrorCnt, errs)
            }
        })
    }
}
```

**Checklist:**
- [ ] String edge cases tested
- [ ] Number edge cases tested
- [ ] Identifier edge cases tested
- [ ] Whitespace handling tested
- [ ] Line number tracking tested
- [ ] Error cases comprehensive
- [ ] All new tests passing

---

### 3. Test Documentation (30 min)

**Objective:** Document testing approach and create testing guide.

**Create test documentation:**

Add section to README or create `docs/testing-guide.md`:

```markdown
# Testing Guide

## Test Organization

### Unit Tests
- `pkg/tokens/token_test.go` - Token type tests
- `pkg/lexer/scanner_test.go` - Scanner unit tests

### Integration Tests
- `pkg/lexer/integration_test.go` - Full program scanning

### Test Categories

1. **Happy Path Tests:** Valid Lox code
2. **Edge Case Tests:** Boundary conditions
3. **Error Tests:** Invalid input handling
4. **Integration Tests:** Complete programs

## Running Tests

```bash
# All tests
go test ./...

# With coverage
go test ./... -cover

# Verbose output
go test ./... -v

# Specific package
go test ./pkg/lexer

# Specific test
go test -run TestScanTokens_Strings ./pkg/lexer
```

## Coverage Goals

- Overall: 80%+
- Core logic (scanner.go): 90%+
- Token types: 100%

## Adding New Tests

1. Identify uncovered code paths
2. Write test case
3. Verify it fails first (TDD)
4. Implement fix
5. Verify test passes
```

**Update inline test documentation:**

Add comments to test files explaining test structure:

```go
// TestScanTokens_SingleCharacters verifies that all single-character
// tokens are recognized correctly. This is a fundamental test that
// should never fail - if it does, the scanner core is broken.
func TestScanTokens_SingleCharacters(t *testing.T) {
    // ...
}
```

**Checklist:**
- [ ] Testing guide created
- [ ] Test organization documented
- [ ] How to run tests documented
- [ ] Coverage goals documented
- [ ] Key test files have comments
- [ ] Testing philosophy explained

**Final commit:**
```bash
git add .
git commit -m "test: comprehensive edge case testing and documentation

- Add edge cases for strings, numbers, identifiers
- Test error handling thoroughly
- Achieve 80%+ coverage
- Document testing approach
- Add testing guide"
```

---

## üìñ Resources

### Go Testing
- **Go Testing:** [go.dev/doc/tutorial/add-a-test](https://go.dev/doc/tutorial/add-a-test)
- **Table-Driven Tests:** [go.dev/wiki/TableDrivenTests](https://go.dev/wiki/TableDrivenTests)
- **Coverage Tools:** [go.dev/blog/cover](https://go.dev/blog/cover)

### Testing Best Practices
- **Test Naming:** [naming-tests](https://rakyll.org/go-test-naming/)
- **Effective Testing:** [effective-testing](https://dave.cheney.net/2019/05/07/prefer-table-driven-tests)

---

## üí° Key Learning Points

### Test Coverage Insights

**High coverage doesn't mean perfect testing:**
- 100% coverage can still miss edge cases
- Focus on meaningful tests, not just coverage %
- Test behavior, not implementation

**Coverage helps identify:**
- Dead code (never executed)
- Missing error handling tests
- Uncovered edge cases

### Edge Case Categories

1. **Boundary values:** 0, empty, max
2. **Invalid input:** Unexpected characters
3. **State transitions:** Multi-character tokens
4. **Error conditions:** Unterminated strings

### Testing Philosophy

**Test pyramid:**
- Many unit tests (fast, focused)
- Some integration tests (realistic)
- Few end-to-end tests (slow, comprehensive)

**For a lexer:**
- Unit: Individual token types
- Integration: Complete programs
- E2E: REPL and file scanning

---

## ‚úÖ Daily Checklist

- [ ] All tests passing (go test ./...)
- [ ] Coverage report generated and reviewed
- [ ] Coverage meets 80%+ target
- [ ] Edge cases identified and tested
- [ ] Error handling tested thoroughly
- [ ] Testing guide documented
- [ ] Test files have explanatory comments
- [ ] All changes committed
- [ ] Learning notes updated

**Planned Time:** 2.5 hours

---

## üîó Navigation

- [‚Üê Day 023](Day-023.md)
- [‚Üí Day 025](Day-025.md)
- [‚Üë Month Overview](README.md)

---

## üìä Coverage Report Template

Document your coverage results:

```
=== Test Coverage Report ===
Date: [Fill in]

Overall Coverage: [X]%

Package Breakdown:
- pkg/tokens:  [X]%
- pkg/lexer:   [X]%
- cmd/lox:     [X]%

Uncovered Areas:
1. [Description]
2. [Description]

Why not 100%:
- [Explanation of acceptable gaps]

Action Items:
- [Any tests to add]
```

---

*Progress: 24/30 days complete* ‚≠ê

**Note:** Comprehensive testing gives you confidence that your lexer works correctly. This is the foundation for building the parser!
