# Day 004: Scanner Core Structure

**Month 1:** Lox Lexer & Go Fundamentals
**Phase:** Foundation
**Week:** 1 of 4 - Go Setup & Token Types

---

## üéØ Today's Goal

Build the Scanner struct - the heart of your lexer. The Scanner reads source code character by character, maintaining state (current position, line number), and will eventually produce tokens. Today you'll create the structure and basic scanning loop.

**What You'll Build:** Complete Scanner struct with core methods (advance, isAtEnd, ScanTokens).

---

## üìö What You'll Learn Today

**Go Fundamentals:**
- Struct fields and initialization
- Methods vs functions
- Slice operations and append
- String indexing (byte access)

**Scanner Algorithm:**
- Character-by-character reading
- Position tracking (start, current)
- Line number tracking
- Token accumulation

---

## ‚úÖ Today's Tasks

### Task 1: Define Scanner Struct (25 minutes)

**What to do:**
Create the Scanner struct that holds all state needed for lexical analysis.

**Create file: `pkg/lexer/scanner.go`**

```go
package lexer

import (
	"github.com/bhargav/konfiguru/pkg/tokens"
)

// Scanner reads Lox source code and produces tokens
type Scanner struct {
	source  string         // The source code being scanned
	tokens  []tokens.Token // The list of tokens produced
	start   int            // Start position of current token
	current int            // Current position in source
	line    int            // Current line number
	errors  []string       // Scanning errors
}

// NewScanner creates a new scanner for the given source code
func NewScanner(source string) *Scanner {
	return &Scanner{
		source:  source,
		tokens:  make([]tokens.Token, 0),
		start:   0,
		current: 0,
		line:    1,
		errors:  make([]string, 0),
	}
}
```

**Understanding the fields:**
- `source`: The entire Lox program as a string
- `tokens`: Accumulates all scanned tokens
- `start`: Beginning of the token currently being scanned
- `current`: Character we're currently examining
- `line`: Track line numbers for error reporting
- `errors`: Collect all scanning errors

**Why return *Scanner?**
The Scanner will be modified as it scans, so we return a pointer. This allows methods to modify the scanner's state.

**Visualization:**
```
source: "var x = 5;"
         ^     ^
         |     |
       start  current
```

---

### Task 2: Implement Core Helper Methods (30 minutes)

**What to do:**
Add essential methods for navigating through source code.

**Add to `pkg/lexer/scanner.go`:**

```go
// isAtEnd checks if we've consumed all characters
func (s *Scanner) isAtEnd() bool {
	return s.current >= len(s.source)
}

// advance consumes the current character and returns it
func (s *Scanner) advance() byte {
	char := s.source[s.current]
	s.current++
	return char
}
```

**Understanding advance():**
```go
// Before: current = 0, source = "var"
char := s.advance()
// After:  current = 1, char = 'v'

char = s.advance()
// After:  current = 2, char = 'a'
```

The `advance()` method:
1. Gets current character
2. Moves position forward
3. Returns the character

**Why bytes, not runes?**
Lox only uses ASCII characters, so we can work with bytes. For Unicode support (in Konfiguru later), you'd use runes.

---

### Task 3: Implement ScanTokens Main Loop (35 minutes)

**What to do:**
Create the main scanning loop that processes the entire source.

**Add to `pkg/lexer/scanner.go`:**

```go
// ScanTokens scans all tokens from the source code
func (s *Scanner) ScanTokens() ([]tokens.Token, []string) {
	for !s.isAtEnd() {
		// We are at the beginning of the next lexeme
		s.start = s.current
		s.scanToken()
	}

	// Add EOF token
	s.tokens = append(s.tokens, tokens.NewToken(
		tokens.EOF,
		"",
		nil,
		s.line,
	))

	return s.tokens, s.errors
}

// scanToken scans a single token
func (s *Scanner) scanToken() {
	// Will be implemented in next days
	// For now, just consume characters
	c := s.advance()
	_ = c // Placeholder to avoid unused variable error
}
```

**How the loop works:**
```
1. Start of loop: start = current = 0
2. Call scanToken() - scans one token
3. Move start to current
4. Repeat until end of source
5. Add EOF token
6. Return tokens and any errors
```

**Why EOF token?**
The parser (Month 2) needs to know when it's reached the end of input. EOF is a special marker token.

---

### Task 4: Write Basic Scanner Tests (30 minutes)

**What to do:**
Test that the Scanner struct and basic methods work correctly.

**Create file: `pkg/lexer/scanner_test.go`**

```go
package lexer

import (
	"testing"

	"github.com/bhargav/konfiguru/pkg/tokens"
)

func TestNewScanner(t *testing.T) {
	source := "var x = 5;"
	scanner := NewScanner(source)

	if scanner.source != source {
		t.Errorf("scanner.source = %q, want %q", scanner.source, source)
	}
	if scanner.line != 1 {
		t.Errorf("scanner.line = %d, want 1", scanner.line)
	}
	if scanner.current != 0 {
		t.Errorf("scanner.current = %d, want 0", scanner.current)
	}
	if scanner.start != 0 {
		t.Errorf("scanner.start = %d, want 0", scanner.start)
	}
}

func TestScanTokens_Empty(t *testing.T) {
	scanner := NewScanner("")
	toks, errs := scanner.ScanTokens()

	if len(errs) != 0 {
		t.Errorf("got %d errors, want 0: %v", len(errs), errs)
	}

	if len(toks) != 1 {
		t.Fatalf("got %d tokens, want 1 (EOF)", len(toks))
	}

	if toks[0].Type != tokens.EOF {
		t.Errorf("token type = %v, want EOF", toks[0].Type)
	}
}

func TestIsAtEnd(t *testing.T) {
	tests := []struct {
		name    string
		source  string
		current int
		want    bool
	}{
		{"at beginning", "hello", 0, false},
		{"in middle", "hello", 2, false},
		{"at last char", "hello", 4, false},
		{"at end", "hello", 5, true},
		{"past end", "hello", 10, true},
		{"empty source", "", 0, true},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			scanner := NewScanner(tt.source)
			scanner.current = tt.current
			got := scanner.isAtEnd()
			if got != tt.want {
				t.Errorf("isAtEnd() = %v, want %v", got, tt.want)
			}
		})
	}
}

func TestAdvance(t *testing.T) {
	scanner := NewScanner("abc")

	// First character
	if got := scanner.advance(); got != 'a' {
		t.Errorf("advance() = %c, want 'a'", got)
	}
	if scanner.current != 1 {
		t.Errorf("current = %d, want 1", scanner.current)
	}

	// Second character
	if got := scanner.advance(); got != 'b' {
		t.Errorf("advance() = %c, want 'b'", got)
	}
	if scanner.current != 2 {
		t.Errorf("current = %d, want 2", scanner.current)
	}

	// Third character
	if got := scanner.advance(); got != 'c' {
		t.Errorf("advance() = %c, want 'c'", got)
	}
	if scanner.current != 3 {
		t.Errorf("current = %d, want 3", scanner.current)
	}

	// Should be at end now
	if !scanner.isAtEnd() {
		t.Error("expected scanner to be at end")
	}
}
```

**Run the tests:**
```bash
go test ./pkg/lexer -v
```

**Expected output:**
```
=== RUN   TestNewScanner
--- PASS: TestNewScanner (0.00s)
=== RUN   TestScanTokens_Empty
--- PASS: TestScanTokens_Empty (0.00s)
=== RUN   TestIsAtEnd
--- PASS: TestIsAtEnd (0.00s)
=== RUN   TestAdvance
--- PASS: TestAdvance (0.00s)
PASS
ok      github.com/bhargav/konfiguru/pkg/lexer
```

---

### Task 5: Verify Build and Integration (15 minutes)

**What to do:**
Ensure everything compiles together and runs.

**Check the whole project builds:**
```bash
cd /home/bhargav/Documents/Side-Projects/konfiguru
go build ./...
```

**Run all tests:**
```bash
go test ./...
```

**Expected output:**
```
?       github.com/bhargav/konfiguru/cmd/lox    [no test files]
ok      github.com/bhargav/konfiguru/pkg/lexer  0.002s
ok      github.com/bhargav/konfiguru/pkg/tokens 0.001s
```

**Check test coverage:**
```bash
go test ./pkg/lexer -cover
```

---

### Task 6: Commit Scanner Structure (15 minutes)

**What to do:**
Commit the scanner skeleton to git.

```bash
git status
# Should show: pkg/lexer/scanner.go, pkg/lexer/scanner_test.go

git add pkg/lexer/
git commit -m "feat: add scanner core structure

- Define Scanner struct with source, tokens, position tracking
- Implement NewScanner() constructor
- Add core methods: isAtEnd(), advance()
- Implement ScanTokens() main loop skeleton
- Add scanToken() placeholder (to be implemented)
- Include comprehensive tests for scanner basics

Scanner can now:
- Initialize with source code
- Track current position and line number
- Navigate character by character
- Return EOF token for empty input

Next: Implement actual token scanning logic.

Ref: Crafting Interpreters Chapter 4.4 (Scanning)"
```

---

## üìñ Resources

**Essential:**
- [Crafting Interpreters - 4.4 The Scanner Class](https://craftinginterpreters.com/scanning.html#the-scanner-class)
- [Go by Example: Structs](https://gobyexample.com/structs)
- [Go by Example: Methods](https://gobyexample.com/methods)

**Go Deep Dive:**
- [Effective Go - Methods](https://go.dev/doc/effective_go#methods)
- [Go Slices Usage and Internals](https://go.dev/blog/slices-intro)

---

## ‚úÖ End-of-Day Checklist

- [ ] `pkg/lexer/scanner.go` created
- [ ] Scanner struct defined with 6 fields
- [ ] NewScanner() constructor implemented
- [ ] isAtEnd() method implemented and tested
- [ ] advance() method implemented and tested
- [ ] ScanTokens() loop implemented
- [ ] scanToken() placeholder created
- [ ] `pkg/lexer/scanner_test.go` created with 4 test functions
- [ ] All tests passing: `go test ./pkg/lexer -v`
- [ ] Full project builds: `go build ./...`
- [ ] Committed to git
- [ ] Tomorrow's plan reviewed (Day 005: Single-character token scanning)

**Time Spent:** ~2.5 hours (25+30+35+30+15+15 = 150 minutes)

**What you built today:**
```go
// Scanner can now:
Scanner struct          // State tracking
NewScanner(source)      // Initialization
isAtEnd()              // End detection
advance()              // Character consumption
ScanTokens()           // Main loop
scanToken()            // Placeholder for logic
```

---

## üîó Navigation

- [‚Üê Day 003: Token Types Tests](Day-003.md)
- [‚Üí Day 005: Single-Character Token Scanning](Day-005.md)
- [‚Üë Back to Month 1](README.md)

---

## üìù Learning Notes

**What did we accomplish?**
You built the skeleton of your lexer. The Scanner can now read through source code character by character, tracking its position and line number. The actual token recognition logic comes next.

**Key Go concepts learned:**
1. **Pointer receivers**: `func (s *Scanner)` - methods can modify the struct
2. **make()**: `make([]tokens.Token, 0)` - creates empty slice with capacity
3. **Byte access**: `s.source[i]` - strings can be indexed as bytes in Go
4. **Multiple returns**: `ScanTokens() ([]tokens.Token, []string)` - Go idiom for returning values + errors

**Scanner state machine:**
The scanner maintains invariants:
- `start <= current <= len(source)` always
- `line >= 1` always
- After each token, `start` moves to `current`

**Why separate start and current?**
```
Source: "var x"
         ^^^
Start:   0     (beginning of "var")
Current: 3     (after "var")

Lexeme: source[start:current] = "var"
```

This lets us extract the token's text when we're done scanning it.

**Tomorrow's preview:**
You'll implement the first real token scanning - single-character operators like `(`, `)`, `+`, `-`, etc. The scanToken() placeholder becomes real!

---

*Progress: Day 4/30 complete* ‚≠ê‚≠ê‚≠ê‚≠ê
*Module: Scanner Core*

**Milestone:** Scanner structure complete. Ready to scan actual tokens!
