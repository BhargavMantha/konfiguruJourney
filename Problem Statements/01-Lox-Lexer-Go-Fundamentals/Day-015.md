# Day 015: Integration Test Suite (Part 1)

**Month 1:** Lox Lexer & Go Fundamentals
**Phase:** Foundation
**Week:** 3 of 4 - Integration Testing & REPL Development

---

## ðŸŽ¯ Today's Goal

Create a comprehensive integration test suite that validates the lexer against complete Lox programs. Test all scanning features working together: operators, literals, keywords, and error handling.

**What You'll Build:** `integration_test.go` with tests for complete programs (variables, expressions, basic control flow).

---

## ðŸ“š What You'll Learn Today

**Go Fundamentals:**
- Integration testing patterns and best practices
- Test organization for complex scenarios
- Multi-file test suite management

**Compiler Concepts:**
- End-to-end tokenization testing
- Validating token sequences
- Verifying lexer correctness for real programs

**Testing Strategy:**
- Unit tests test individual features
- Integration tests verify features work together
- Real-world program scanning validates production readiness

---

## âœ… Today's Tasks

### Task 1: Create Integration Test File (15 minutes)

**What to do:**
Create the integration test file with basic setup.

**Create file: `pkg/lexer/integration_test.go`:**

```go
package lexer

import (
	"testing"

	"github.com/bhargav/konfiguru/pkg/tokens"
)

// Integration tests verify that all lexer features work together
// to scan complete, real-world Lox programs.
```

**Why integration tests matter:**
- Unit tests verify individual features (strings, numbers, keywords)
- Integration tests ensure those features work together
- They catch issues that only appear in real program contexts

---

### Task 2: Test Complete Variable Programs (45 minutes)

**What to do:**
Write tests for programs with variable declarations and various literal types.

**Add to `pkg/lexer/integration_test.go`:**

```go
func TestScanTokens_CompleteProgram(t *testing.T) {
	source := `
var x = 10;
var y = 20;
var result = x + y;
print result;
`

	scanner := NewScanner(source)
	toks, errs := scanner.ScanTokens()

	if len(errs) != 0 {
		t.Fatalf("got errors: %v", errs)
	}

	expected := []tokens.TokenType{
		tokens.VAR, tokens.IDENTIFIER, tokens.EQUAL, tokens.NUMBER, tokens.SEMICOLON,
		tokens.VAR, tokens.IDENTIFIER, tokens.EQUAL, tokens.NUMBER, tokens.SEMICOLON,
		tokens.VAR, tokens.IDENTIFIER, tokens.EQUAL, tokens.IDENTIFIER, tokens.PLUS,
		tokens.IDENTIFIER, tokens.SEMICOLON,
		tokens.PRINT, tokens.IDENTIFIER, tokens.SEMICOLON,
		tokens.EOF,
	}

	if len(toks) != len(expected) {
		t.Fatalf("got %d tokens, want %d", len(toks), len(expected))
	}

	for i, expectedType := range expected {
		if toks[i].Type != expectedType {
			t.Errorf("token[%d] = %v, want %v", i, toks[i].Type, expectedType)
		}
	}
}

func TestScanTokens_MixedLiterals(t *testing.T) {
	source := `var name = "Alice";
var age = 25;
var pi = 3.14159;
var active = true;
var nothing = nil;

print name;
print age;`

	scanner := NewScanner(source)
	toks, errs := scanner.ScanTokens()

	if len(errs) != 0 {
		t.Fatalf("unexpected errors: %v", errs)
	}

	// Count different token types
	counts := make(map[tokens.TokenType]int)
	for _, tok := range toks {
		counts[tok.Type]++
	}

	// Verify we have the expected counts
	expected := map[tokens.TokenType]int{
		tokens.VAR:   5, // 5 variable declarations
		tokens.PRINT: 2, // 2 print statements
	}

	for tokenType, expectedCount := range expected {
		if counts[tokenType] != expectedCount {
			t.Errorf("token %v: got %d, want %d",
				tokenType, counts[tokenType], expectedCount)
		}
	}

	// Verify we have at least one of each literal type
	if counts[tokens.STRING] < 1 {
		t.Error("expected at least one STRING token")
	}
	if counts[tokens.NUMBER] < 2 {
		t.Error("expected at least two NUMBER tokens")
	}
	if counts[tokens.TRUE] < 1 {
		t.Error("expected TRUE keyword")
	}
	if counts[tokens.NIL] < 1 {
		t.Error("expected NIL keyword")
	}
}
```

**Run the tests:**
```bash
go test ./pkg/lexer -v -run TestScanTokens_Complete
```

Expected: Tests pass

---

### Task 3: Test Expression Scanning (45 minutes)

**What to do:**
Add tests for complex mathematical and logical expressions.

**Add to `pkg/lexer/integration_test.go`:**

```go
func TestScanTokens_ComplexExpression(t *testing.T) {
	source := `(5 + 3) * 2 - 7 / 2.5 >= 10 and true or false`

	scanner := NewScanner(source)
	toks, errs := scanner.ScanTokens()

	if len(errs) != 0 {
		t.Fatalf("got errors: %v", errs)
	}

	expected := []tokens.TokenType{
		tokens.LEFT_PAREN,
		tokens.NUMBER,       // 5
		tokens.PLUS,
		tokens.NUMBER,       // 3
		tokens.RIGHT_PAREN,
		tokens.STAR,
		tokens.NUMBER,       // 2
		tokens.MINUS,
		tokens.NUMBER,       // 7
		tokens.SLASH,
		tokens.NUMBER,       // 2.5
		tokens.GREATER_EQUAL,
		tokens.NUMBER,       // 10
		tokens.AND,
		tokens.TRUE,
		tokens.OR,
		tokens.FALSE,
		tokens.EOF,
	}

	if len(toks) != len(expected) {
		t.Fatalf("got %d tokens, want %d", len(toks), len(expected))
	}

	for i, expectedType := range expected {
		if toks[i].Type != expectedType {
			t.Errorf("token[%d] = %v, want %v", i, toks[i].Type, expectedType)
		}
	}
}

func TestScanTokens_ArithmeticExpressions(t *testing.T) {
	tests := []struct {
		name   string
		source string
		verify func(t *testing.T, toks []tokens.Token)
	}{
		{
			name:   "basic arithmetic",
			source: "1 + 2 - 3 * 4 / 5",
			verify: func(t *testing.T, toks []tokens.Token) {
				// Should have 5 numbers and 4 operators + EOF
				if len(toks) != 10 {
					t.Errorf("got %d tokens, want 10", len(toks))
				}
			},
		},
		{
			name:   "parenthesized expression",
			source: "((10 + 5) * 2) - (3 / 1.5)",
			verify: func(t *testing.T, toks []tokens.Token) {
				// Count parentheses
				parenCount := 0
				for _, tok := range toks {
					if tok.Type == tokens.LEFT_PAREN || tok.Type == tokens.RIGHT_PAREN {
						parenCount++
					}
				}
				if parenCount != 8 {
					t.Errorf("got %d parentheses, want 8", parenCount)
				}
			},
		},
		{
			name:   "comparison operators",
			source: "x > 5 and y <= 10 or z != 0",
			verify: func(t *testing.T, toks []tokens.Token) {
				// Should have comparison operators
				hasGreater := false
				hasLessEqual := false
				hasBangEqual := false
				for _, tok := range toks {
					if tok.Type == tokens.GREATER {
						hasGreater = true
					}
					if tok.Type == tokens.LESS_EQUAL {
						hasLessEqual = true
					}
					if tok.Type == tokens.BANG_EQUAL {
						hasBangEqual = true
					}
				}
				if !hasGreater || !hasLessEqual || !hasBangEqual {
					t.Error("missing expected comparison operators")
				}
			},
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			scanner := NewScanner(tt.source)
			toks, errs := scanner.ScanTokens()

			if len(errs) != 0 {
				t.Fatalf("unexpected errors: %v", errs)
			}

			tt.verify(t, toks)
		})
	}
}
```

**Run:**
```bash
go test ./pkg/lexer -v -run TestScanTokens_.*Expression
```

Expected: All expression tests pass

---

### Task 4: Test Print Statements (30 minutes)

**What to do:**
Test programs with multiple print statements and various argument types.

**Add to `pkg/lexer/integration_test.go`:**

```go
func TestScanTokens_PrintStatements(t *testing.T) {
	source := `print "Hello, World!";
print 42;
print 3.14159;
print true;
print nil;
print x + y;`

	scanner := NewScanner(source)
	toks, errs := scanner.ScanTokens()

	if len(errs) != 0 {
		t.Fatalf("got errors: %v", errs)
	}

	// Count print keywords
	printCount := 0
	for _, tok := range toks {
		if tok.Type == tokens.PRINT {
			printCount++
		}
	}

	if printCount != 6 {
		t.Errorf("got %d print statements, want 6", printCount)
	}

	// Verify all tokens are present (no scanning errors that skipped tokens)
	// Should have: 6 PRINT + 6 arguments + 6 SEMICOLON + 1 EOF + operators for last print
	if len(toks) < 19 {
		t.Errorf("got %d tokens, expected at least 19", len(toks))
	}
}

func TestScanTokens_StringConcatenation(t *testing.T) {
	source := `var message = "Hello, " + "World" + "!";
print message;`

	scanner := NewScanner(source)
	toks, errs := scanner.ScanTokens()

	if len(errs) != 0 {
		t.Fatalf("got errors: %v", errs)
	}

	// Count string literals
	stringCount := 0
	for _, tok := range toks {
		if tok.Type == tokens.STRING {
			stringCount++
		}
	}

	if stringCount != 3 {
		t.Errorf("got %d strings, want 3", stringCount)
	}

	// Verify PLUS operators for concatenation
	plusCount := 0
	for _, tok := range toks {
		if tok.Type == tokens.PLUS {
			plusCount++
		}
	}

	if plusCount != 2 {
		t.Errorf("got %d PLUS operators, want 2", plusCount)
	}
}
```

**Run:**
```bash
go test ./pkg/lexer -v -run TestScanTokens_Print
```

---

### Task 5: Test Line Number Tracking (30 minutes)

**What to do:**
Verify that line numbers are correctly tracked across multiline programs.

**Add to `pkg/lexer/integration_test.go`:**

```go
func TestScanTokens_LineNumberTracking(t *testing.T) {
	source := `var x = 1;
var y = 2;
var z = 3;
print x;
print y;
print z;`

	scanner := NewScanner(source)
	toks, errs := scanner.ScanTokens()

	if len(errs) != 0 {
		t.Fatalf("got errors: %v", errs)
	}

	// First VAR should be on line 1
	if toks[0].Type == tokens.VAR && toks[0].Line != 1 {
		t.Errorf("first VAR on line %d, want line 1", toks[0].Line)
	}

	// Find the first PRINT (should be on line 4)
	for _, tok := range toks {
		if tok.Type == tokens.PRINT {
			if tok.Line != 4 {
				t.Errorf("first PRINT on line %d, want line 4", tok.Line)
			}
			break
		}
	}
}

func TestScanTokens_MultilineString(t *testing.T) {
	source := `var message = "This is
a multiline
string";
print message;`

	scanner := NewScanner(source)
	toks, errs := scanner.ScanTokens()

	if len(errs) != 0 {
		t.Fatalf("got errors: %v", errs)
	}

	// The string starts on line 1
	for _, tok := range toks {
		if tok.Type == tokens.STRING {
			if tok.Line != 1 {
				t.Errorf("STRING token on line %d, want line 1", tok.Line)
			}
			break
		}
	}

	// PRINT should be on line 4 (after 3-line string)
	for _, tok := range toks {
		if tok.Type == tokens.PRINT {
			if tok.Line != 4 {
				t.Errorf("PRINT on line %d, want line 4", tok.Line)
			}
			break
		}
	}
}
```

**Run:**
```bash
go test ./pkg/lexer -v -run TestScanTokens_Line
```

---

### Task 6: Run Complete Integration Test Suite (15 minutes)

**Run all integration tests:**
```bash
# Run only integration tests
go test ./pkg/lexer -v -run Integration

# Or run all lexer tests
go test ./pkg/lexer -v

# With coverage
go test ./pkg/lexer -cover
```

**Verify:**
- All tests passing
- No unexpected failures
- Coverage remains high

**Check overall project status:**
```bash
# Run all project tests
go test ./... -v

# Build to ensure no compilation errors
make build
```

---

### Task 7: Commit Integration Tests (10 minutes)

**Git commit:**
```bash
git add pkg/lexer/integration_test.go
git commit -m "test: add integration tests for complete programs (Part 1)

- Test complete variable declaration programs
- Test mixed literal types (strings, numbers, booleans, nil)
- Test complex arithmetic and logical expressions
- Test print statements with various argument types
- Test line number tracking across multiline programs
- Verify all lexer features work together correctly

Maps to Task 10 (Integration Test Suite), Steps 1-2

Day 15/30: Integration testing foundation"
```

---

## ðŸ“– Resources

**Integration Testing:**
- [Go Testing Package](https://pkg.go.dev/testing)
- [Table-Driven Tests](https://dave.cheney.net/2019/05/07/prefer-table-driven-tests)
- [Effective Go - Testing](https://go.dev/doc/effective_go#testing)

**Crafting Interpreters:**
- [Chapter 4 - Testing the Scanner](https://craftinginterpreters.com/scanning.html#testing-the-scanner)

---

## âœ… End-of-Day Checklist

- [ ] Created `integration_test.go` file
- [ ] Wrote tests for complete variable programs
- [ ] Wrote tests for complex expressions
- [ ] Wrote tests for print statements
- [ ] Wrote tests for line number tracking
- [ ] All integration tests passing: `go test ./pkg/lexer -v -run Integration`
- [ ] All project tests passing: `go test ./... -v`
- [ ] Code committed to git
- [ ] Updated Obsidian notes with learnings

**Time Spent:** ~3 hours (15+45+45+30+30+15+10 = 190 minutes)

**What you should have:**
- Complete integration test suite covering basic programs
- Confidence that all lexer features work together
- Foundation for tomorrow's more complex tests

---

## ðŸ”— Navigation

- [â† Day 014: Week 2 Review](Day-014.md)
- [â†’ Day 016: Integration Tests - Complex Programs](Day-016.md)
- [â†‘ Month Overview](README.md)

---

## ðŸ“ Learning Notes

**Integration Testing Best Practices:**

1. **Test Real Scenarios:**
   - Use actual Lox programs, not contrived examples
   - Mix different token types in each test
   - Verify tokens appear in correct sequence

2. **Use Helper Functions:**
   - Count tokens by type (helps verify completeness)
   - Check for presence of key tokens
   - Validate token sequences when order matters

3. **Meaningful Assertions:**
   - Don't just count tokens - verify they're correct
   - Check line numbers for multiline programs
   - Verify literal values when relevant

4. **Organization:**
   - Group related tests together
   - Use descriptive test names
   - Add comments explaining what each test validates

**Integration vs Unit Tests:**

| Unit Tests | Integration Tests |
|------------|-------------------|
| Test one feature | Test features together |
| Fast, focused | Slower, comprehensive |
| Easy to debug | Catch interaction bugs |
| Many small tests | Fewer large tests |

**What We Verified Today:**
- âœ… Variables with all literal types scan correctly
- âœ… Complex expressions with multiple operators work
- âœ… Print statements with various arguments work
- âœ… Line numbers track correctly across multiline programs
- âœ… All token types work together without conflicts

**Tomorrow Preview:**
We'll add integration tests for more complex Lox constructs:
- If/else statements
- Function declarations
- Loops (for, while)
- Classes

---

*Progress: Day 15/30 complete* â­
*Week 3: Integration Testing & REPL Development*

**Great work! You're testing like a professional compiler engineer!**
