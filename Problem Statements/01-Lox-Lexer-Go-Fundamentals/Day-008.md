# Day 008: String Literal Scanning (Part 1)

**Month 1:** Lox Lexer & Go Fundamentals
**Phase:** Foundation
**Week:** 2 of 4 - Literals & Advanced Scanning

---

## üéØ Today's Goal

Implement string literal scanning in the Lox lexer. By the end of today, you'll have a working `scanString()` method that can tokenize basic string literals enclosed in double quotes.

**What You'll Build:** String scanning functionality that handles quoted text and stores the string value (without quotes) as the token's literal.

---

## üìö What You'll Learn Today

**Go Fundamentals:**
- String slicing in Go (`source[start:end]`)
- Escape sequences and string handling
- Working with byte slices vs runes

**Compiler Concepts:**
- String token representation
- Literal value extraction
- Quote handling in scanners

**Crafting Interpreters:**
- Section 4.6 (String Literals) - Read first!

---

## ‚úÖ Today's Tasks

### Task 1: Review String Scanning Algorithm (20 minutes)

**What to do:**
Read Crafting Interpreters Section 4.6 and understand the string scanning algorithm.

**Key concepts to understand:**
1. How to detect the start of a string (opening `"`)
2. How to consume characters until closing `"`
3. How to extract the value (text between quotes)
4. Why we need to track line numbers inside strings

**Pseudocode algorithm:**
```
when we see a " character:
  advance past the opening quote
  while current character is not " and not at end:
    consume the character
  if at end:
    error: unterminated string
  else:
    advance past the closing quote
    extract value (text between quotes)
    add STRING token with value
```

**Resources:**
- [Crafting Interpreters - String Literals](https://craftinginterpreters.com/scanning.html#string-literals)
- [Go Strings](https://go.dev/blog/strings)

---

### Task 2: Implement scanString() Method (45 minutes)

**What to do:**
Add the `scanString()` method to your scanner that handles basic string literals.

**Step-by-step implementation:**

1. **Open your scanner file:**
```bash
cd /home/bhargav/Documents/Side-Projects/konfiguru
code pkg/lexer/scanner.go
```

2. **Add the scanString method:**
Add this method to your `Scanner` struct in `pkg/lexer/scanner.go`:

```go
// scanString scans a string literal
func (s *Scanner) scanString() {
	// Consume characters until we hit the closing quote or end of file
	for s.peek() != '"' && !s.isAtEnd() {
		s.advance()
	}

	if s.isAtEnd() {
		s.addError("Unterminated string.")
		return
	}

	// Consume the closing "
	s.advance()

	// Trim the surrounding quotes to get the actual string value
	// start+1 skips the opening quote, current-1 skips the closing quote
	value := s.source[s.start+1 : s.current-1]
	s.addTokenLiteral(tokens.STRING, value)
}
```

**Understanding the code:**
- `s.peek() != '"'` - Check if current char is NOT a closing quote
- `!s.isAtEnd()` - Make sure we haven't reached end of source
- `s.advance()` - Consume each character in the string
- `s.source[s.start+1 : s.current-1]` - Extract the string value WITHOUT the quotes
  - `s.start` points to the opening `"`
  - `s.start+1` is the first character of the actual string
  - `s.current-1` is the last character before the closing `"`

**Example:**
```
Source: "hello"
        ^     ^
      start current
        0     6

Value extraction: source[1:5] = "hello" (without quotes)
```

3. **Add the case for double-quote in scanToken():**

Find the `scanToken()` method and add this case before the `default` case:

```go
	case '"':
		s.scanString()
```

**Verify your changes:**
```bash
# Make sure the file compiles
go build ./pkg/lexer
```

Expected: No errors

---

### Task 3: Write Basic String Tests (40 minutes)

**What to do:**
Write tests to verify string scanning works correctly.

**Step-by-step:**

1. **Open the test file:**
```bash
code pkg/lexer/scanner_test.go
```

2. **Add test for basic strings:**
Add this test function to `scanner_test.go`:

```go
func TestScanTokens_Strings_Basic(t *testing.T) {
	tests := []struct {
		source      string
		wantLiteral string
	}{
		{`"hello"`, "hello"},
		{`"world"`, "world"},
		{`""`, ""}, // empty string
		{`"hello world"`, "hello world"}, // string with space
		{`"abc123"`, "abc123"}, // string with numbers
	}

	for _, tt := range tests {
		scanner := NewScanner(tt.source)
		toks, errs := scanner.ScanTokens()

		// Should have no errors
		if len(errs) != 0 {
			t.Errorf("source %q: unexpected errors %v", tt.source, errs)
			continue
		}

		// Should have exactly 2 tokens: STRING + EOF
		if len(toks) != 2 {
			t.Fatalf("source %q: got %d tokens, want 2 (STRING + EOF)",
				tt.source, len(toks))
		}

		// First token should be STRING type
		if toks[0].Type != tokens.STRING {
			t.Errorf("source %q: token type = %v, want STRING",
				tt.source, toks[0].Type)
		}

		// Literal should match the string content (without quotes)
		if toks[0].Literal != tt.wantLiteral {
			t.Errorf("source %q: literal = %q, want %q",
				tt.source, toks[0].Literal, tt.wantLiteral)
		}

		// Lexeme should include the quotes
		expectedLexeme := `"` + tt.wantLiteral + `"`
		if toks[0].Lexeme != expectedLexeme {
			t.Errorf("source %q: lexeme = %q, want %q",
				tt.source, toks[0].Lexeme, expectedLexeme)
		}
	}
}
```

**Understanding the test:**
- We test various string inputs
- Verify the token type is STRING
- Verify the literal value (without quotes)
- Verify the lexeme (with quotes)

3. **Run the tests:**
```bash
go test ./pkg/lexer -v -run TestScanTokens_Strings_Basic
```

Expected output:
```
=== RUN   TestScanTokens_Strings_Basic
--- PASS: TestScanTokens_Strings_Basic (0.00s)
PASS
```

If tests fail, debug by:
- Checking the `scanString()` implementation
- Verifying the slice indices: `s.start+1` and `s.current-1`
- Adding debug prints: `fmt.Printf("start=%d, current=%d, value=%q\n", s.start, s.current, value)`

---

### Task 4: Test Strings in Expressions (30 minutes)

**What to do:**
Test that strings work correctly when combined with other tokens.

**Add integration test:**

```go
func TestScanTokens_StringsInExpressions(t *testing.T) {
	tests := []struct {
		name   string
		source string
		want   []struct {
			tokenType tokens.TokenType
			literal   interface{}
		}
	}{
		{
			name:   "variable assignment with string",
			source: `var name = "Alice";`,
			want: []struct {
				tokenType tokens.TokenType
				literal   interface{}
			}{
				{tokens.VAR, nil},
				{tokens.IDENTIFIER, nil},
				{tokens.EQUAL, nil},
				{tokens.STRING, "Alice"},
				{tokens.SEMICOLON, nil},
				{tokens.EOF, nil},
			},
		},
		{
			name:   "print statement with string",
			source: `print "Hello, World!";`,
			want: []struct {
				tokenType tokens.TokenType
				literal   interface{}
			}{
				{tokens.PRINT, nil},
				{tokens.STRING, "Hello, World!"},
				{tokens.SEMICOLON, nil},
				{tokens.EOF, nil},
			},
		},
		{
			name:   "multiple strings",
			source: `"first" "second"`,
			want: []struct {
				tokenType tokens.TokenType
				literal   interface{}
			}{
				{tokens.STRING, "first"},
				{tokens.STRING, "second"},
				{tokens.EOF, nil},
			},
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			scanner := NewScanner(tt.source)
			toks, errs := scanner.ScanTokens()

			if len(errs) != 0 {
				t.Fatalf("unexpected errors: %v", errs)
			}

			if len(toks) != len(tt.want) {
				t.Fatalf("got %d tokens, want %d", len(toks), len(tt.want))
			}

			for i, want := range tt.want {
				if toks[i].Type != want.tokenType {
					t.Errorf("token[%d] type = %v, want %v",
						i, toks[i].Type, want.tokenType)
				}
				if want.literal != nil && toks[i].Literal != want.literal {
					t.Errorf("token[%d] literal = %v, want %v",
						i, toks[i].Literal, want.literal)
				}
			}
		})
	}
}
```

**Run the tests:**
```bash
go test ./pkg/lexer -v -run TestScanTokens_StringsInExpressions
```

---

### Task 5: Manual REPL Testing (15 minutes)

**What to do:**
Test string scanning interactively in the REPL.

**Build and run:**
```bash
make build
./lox
```

**Test inputs:**
```
> "hello"
STRING "hello" hello
EOF  <nil>

> var message = "Hello, Lox!";
VAR var <nil>
IDENTIFIER message <nil>
EQUAL = <nil>
STRING "Hello, Lox!" Hello, Lox!
SEMICOLON ; <nil>
EOF  <nil>

> print "test";
PRINT print <nil>
STRING "test" test
SEMICOLON ; <nil>
EOF  <nil>

> exit
```

**What to verify:**
- Strings are tokenized correctly
- Literal value excludes quotes
- Lexeme includes quotes
- Strings work in variable assignments and print statements

---

## üìñ Resources

**Essential:**
- [Crafting Interpreters - String Literals](https://craftinginterpreters.com/scanning.html#string-literals)
- [Go Strings Blog Post](https://go.dev/blog/strings)
- [Go by Example - Strings](https://gobyexample.com/strings)

**Go String Slicing:**
- String indexing in Go uses bytes, not runes
- Format: `str[start:end]` (end is exclusive)
- Examples:
  - `"hello"[0:2]` ‚Üí `"he"`
  - `"hello"[1:]` ‚Üí `"ello"`
  - `"hello"[:4]` ‚Üí `"hell"`

---

## ‚úÖ End-of-Day Checklist

- [ ] Read Crafting Interpreters Section 4.6
- [ ] Implemented `scanString()` method
- [ ] Added string case to `scanToken()`
- [ ] Written basic string tests - all passing
- [ ] Written expression integration tests - all passing
- [ ] Tested strings in REPL manually
- [ ] All tests pass: `go test ./pkg/lexer -v`
- [ ] Code committed to git (see below)

**Git commit:**
```bash
git add pkg/lexer/
git commit -m "feat: implement basic string literal scanning

- Add scanString() method for quoted strings
- Extract string value without surrounding quotes
- Support empty strings and strings with spaces
- Add comprehensive tests for basic string scenarios
- Verify strings work in expressions

Day 8/30: String scanning foundation complete"
```

**Time Spent:** ~2.5 hours (20+45+40+30+15 = 150 minutes)

---

## üîó Navigation

- [‚Üê Day 007: Week 1 Review](Day-007.md)
- [‚Üí Day 009: String Multiline & Error Handling](Day-009.md)
- [‚Üë Month Overview](README.md)

---

## üìù Learning Notes

**Key Concepts Learned:**

1. **String Scanning Algorithm:**
   - Find opening quote ‚Üí consume until closing quote ‚Üí extract value

2. **Go String Slicing:**
   - `source[start:end]` creates a substring
   - Indices are byte positions (not character positions)
   - `source[1:5]` includes index 1-4, excludes 5

3. **Lexeme vs Literal:**
   - **Lexeme:** The raw text including quotes: `"hello"`
   - **Literal:** The actual value without quotes: `hello`

4. **Token Structure:**
   ```go
   Token{
     Type:    STRING,
     Lexeme:  "\"hello\"",  // With quotes
     Literal: "hello",      // Without quotes
     Line:    1,
   }
   ```

**Common Gotchas:**
- Don't forget to advance past the closing quote!
- Slice indices: `start+1` to skip opening `"`, `current-1` to exclude closing `"`
- Test empty strings (`""`) - edge case

**Tomorrow's Preview:**
You'll enhance string scanning to handle:
- Multiline strings (strings that span multiple lines)
- Error handling for unterminated strings
- Line number tracking within strings

---

*Progress: Day 8/30 complete* ‚≠ê
*Week 2: String & Number Literals*

**Commit your daily notes to Obsidian!**
